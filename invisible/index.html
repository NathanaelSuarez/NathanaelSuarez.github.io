<!DOCTYPE html>
<html>
<head>
    <title>Webcam Segmentation</title>
    <style>
        /* styles.css */
        body {
            margin: 0;
            overflow: hidden;
            background: #1a1a1a;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
        }

        .container {
            position: relative;
            width: 640px;
            height: 480px;
        }

        video, canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            transform: scaleX(-1);
        }

        canvas {
            z-index: 2;
        }

        .controls {
            position: absolute;
            bottom: 10px;
            left: 50%;
            transform: translateX(-50%);
            z-index: 3;
        }

        button {
            padding: 10px 20px;
            margin: 0 5px;
            border: none;
            border-radius: 5px;
            background: #4CAF50;
            color: white;
            cursor: pointer;
            transition: background 0.3s;
        }

        button:hover {
            background: #45a049;
        }

        button:disabled {
            background: #cccccc;
            cursor: not-allowed;
        }
    </style>
</head>
<body>
    <div class="container">
        <video id="webcam" playsinline autoplay></video>
        <canvas id="output"></canvas>
        <div class="controls">
            <button id="startButton">Start</button>
            <button id="stopButton">Stop</button>
        </div>
    </div>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/body-segmentation"></script>
    <script>
        // app.js
        let segmenter, isSegmenting, animationFrameId;
        let backgroundCanvas, backgroundCtx;
        const DILATION_RADIUS = 20; // Reduced for less aggressive dilation. Adjust as needed.
        const SEGMENTATION_THRESHOLD = 0.6; // Adjustable threshold.  Start here and tweak.

        const videoElement = document.getElementById('webcam');
        const canvasElement = document.getElementById('output');
        const startButton = document.getElementById('startButton');
        const stopButton = document.getElementById('stopButton');

        async function setupWebcam() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                videoElement.srcObject = stream;
                await new Promise(resolve => videoElement.onloadedmetadata = resolve);
                videoElement.width = videoElement.videoWidth;
                videoElement.height = videoElement.videoHeight;
                canvasElement.width = videoElement.videoWidth;
                canvasElement.height = videoElement.videoHeight;
            } catch (error) {
                console.error('Error accessing webcam:', error);
            }
        }

        async function loadSegmentationModel() {
            await tf.setBackend('webgl');
            await tf.ready();

            segmenter = await bodySegmentation.createSegmenter(
                bodySegmentation.SupportedModels.MediaPipeSelfieSegmentation,
                {
                    runtime: 'mediapipe',
                    modelType: 'full', // Use 'full' for higher accuracy.
                    solutionPath: 'https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation'
                }
            );
        }

        function dilateMask(maskCtx) {
            const width = maskCtx.canvas.width;
            const height = maskCtx.canvas.height;
            const imageData = maskCtx.getImageData(0, 0, width, height);
            const data = imageData.data;
            const dilationRadius = DILATION_RADIUS; // Use constant for performance

            // Horizontal Dilation
            const horizontalPass = new Uint8ClampedArray(data.length);
            for (let y = 0; y < height; y++) {
                for (let x = 0; x < width; x++) {
                    const pixelIndex = (y * width + x) * 4;
                    if (data[pixelIndex + 3] > 0) { // Check alpha channel for foreground
                        for (let dx = -dilationRadius; dx <= dilationRadius; dx++) {
                            const dilatedX = x + dx;
                            if (dilatedX >= 0 && dilatedX < width) {
                                const dilatedPixelIndex = (y * width + dilatedX) * 4;
                                horizontalPass[dilatedPixelIndex + 3] = 255; // Set alpha to opaque
                            }
                        }
                    }
                }
            }

            // Vertical Dilation
            const verticalPass = new Uint8ClampedArray(data.length);
            for (let x = 0; x < width; x++) {
                for (let y = 0; y < height; y++) {
                    const pixelIndex = (y * width + x) * 4;
                    if (horizontalPass[pixelIndex + 3] > 0) { // Check alpha from horizontal pass
                        for (let dy = -dilationRadius; dy <= dilationRadius; dy++) {
                            const dilatedY = y + dy;
                            if (dilatedY >= 0 && dilatedY < height) {
                                const dilatedPixelIndex = (dilatedY * width + x) * 4;
                                verticalPass[dilatedPixelIndex + 3] = 255; // Set alpha to opaque
                            }
                        }
                    }
                }
            }


            // Update ImageData with dilated mask (alpha channel only)
            for (let i = 3; i < data.length; i += 4) {
                data[i] = verticalPass[i];
            }
            maskCtx.putImageData(imageData, 0, 0);
        }


        async function processFrame() {
            if (!isSegmenting) return;

            const people = await segmenter.segmentPeople(videoElement);
            const mask = await bodySegmentation.toBinaryMask(
                people,
                { r: 0, g: 0, b: 0, a: 255 }, // Foreground (person) color: opaque black
                { r: 0, g: 0, b: 0, a: 0 },   // Background color: transparent black
                false,                         // Don't flip the mask horizontally
                SEGMENTATION_THRESHOLD          // Use the adjustable threshold
            );


            const maskCanvas = document.createElement('canvas');
            maskCanvas.width = videoElement.videoWidth;
            maskCanvas.height = videoElement.videoHeight;
            const maskCtx = maskCanvas.getContext('2d');
            maskCtx.putImageData(mask, 0, 0);
            dilateMask(maskCtx);

            // Update output canvas
            const outputCtx = canvasElement.getContext('2d');

            // 1. Draw the background where the mask *is* present (person is masked out).
            outputCtx.drawImage(backgroundCanvas, 0, 0);          // Draw the initial background
            outputCtx.globalCompositeOperation = 'destination-in'; // Keep only pixels where *both* the background and the mask are present.
            outputCtx.drawImage(maskCanvas, 0, 0);                // Apply the mask.

            // 2. Draw the video on top, *filling in* the areas not covered by the mask.
            outputCtx.globalCompositeOperation = 'destination-over'; // Draw the video *behind* what's already on the canvas.
            outputCtx.drawImage(videoElement, 0, 0);               // Draw the current video frame.

            // --- Update background buffer ---

            // Create a temporary canvas to composite the background update.
            const tempCanvas = document.createElement('canvas');
            tempCanvas.width = videoElement.videoWidth;
            tempCanvas.height = videoElement.videoHeight;
            const tempCtx = tempCanvas.getContext('2d');

            // 1. Draw the current video frame.
            tempCtx.drawImage(videoElement, 0, 0);

            // 2. Use 'destination-out' to *remove* the areas where the mask is present (the person).
            tempCtx.globalCompositeOperation = 'destination-out';
            tempCtx.drawImage(maskCanvas, 0, 0);  // Remove the person from the video frame using the mask.

            // 3. Reset the composite operation to 'source-over' (normal drawing).
            tempCtx.globalCompositeOperation = 'source-over';

            // 4. Draw the updated background (only the non-person parts) onto the background canvas.
            backgroundCtx.drawImage(tempCanvas, 0, 0);

            animationFrameId = requestAnimationFrame(processFrame);
        }



        startButton.addEventListener('click', async () => {
            if (!segmenter) {
                await setupWebcam();
                await loadSegmentationModel();
                backgroundCanvas = document.createElement('canvas');
                backgroundCanvas.width = videoElement.videoWidth;
                backgroundCanvas.height = videoElement.videoHeight;
                backgroundCtx = backgroundCanvas.getContext('2d');
                // Capture the very first frame as the initial background.
                backgroundCtx.drawImage(videoElement, 0, 0);
            }

            startButton.disabled = true;
            stopButton.disabled = false;
            isSegmenting = true;
            processFrame();
        });

        stopButton.addEventListener('click', () => {
            isSegmenting = false;
            startButton.disabled = false;
            stopButton.disabled = true;
            cancelAnimationFrame(animationFrameId);
            // Clear the output canvas.
            canvasElement.getContext('2d').clearRect(0, 0, canvasElement.width, canvasElement.height);
        });

        stopButton.disabled = true;
    </script>
</body>
</html>