<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Selfie Rating Predictor</title>
    <style>
        body {
            font-family: sans-serif;
            line-height: 1.6;
            padding: 20px;
            max-width: 800px;
            margin: auto;
            background-color: #f4f4f4;
        }
        h1, h2 {
            text-align: center;
            color: #333;
        }
        .container {
            background-color: #fff;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
            margin-bottom: 20px;
        }
        button {
            padding: 10px 15px;
            font-size: 1em;
            cursor: pointer;
            background-color: #007bff;
            color: white;
            border: none;
            border-radius: 5px;
            transition: background-color 0.3s ease;
            margin: 5px;
        }
        button:disabled {
            background-color: #ccc;
            cursor: not-allowed;
        }
        button:hover:not(:disabled) {
            background-color: #0056b3;
        }
        #status, #trainingStatus, #predictionResult {
            margin-top: 15px;
            font-weight: bold;
            color: #333;
            padding: 10px;
            border: 1px solid #ddd;
            border-radius: 4px;
            background-color: #f9f9f9;
            min-height: 30px;
            white-space: pre-wrap; /* Keep formatting for status */
            word-wrap: break-word;
        }
        #correlationInfo {
             font-size: 0.9em;
             color: #555;
             max-height: 150px;
             overflow-y: auto;
             border-top: 1px solid #eee;
             margin-top: 10px;
             padding-top: 10px;
        }
        .webcam-section {
             text-align: center;
        }
        #webcamVideo {
            display: block;
            margin: 10px auto;
            border: 1px solid #ccc;
            max-width: 100%;
            height: auto;
             background-color: #eee; /* Placeholder bg */
        }
        #captureCanvas {
            display: none; /* Hidden canvas for capturing */
        }
        #capturedImagePreview {
             display: block;
             margin: 10px auto;
             max-width: 200px;
             max-height: 150px;
             border: 1px solid #ddd;
        }
        #predictionResult {
             font-size: 1.2em;
             text-align: center;
             background-color: #e9f5ff;
             border-color: #b8d6f0;
        }
        .note {
            font-size: 0.9em;
            color: #777;
            margin-top: 5px;
        }
    </style>
    <!-- Load TensorFlow.js -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
    <!-- Load Transformers.js (as module) -->
    <!-- REMOVED: <script type="module" src="app.js"></script> -->

</head>
<body>

<h1>Selfie Rating Predictor</h1>

<div class="container">
    <h2>1. Load Data & Train Model</h2>
    <button id="loadTrainButton">Load Data and Train Predictor</button>
    <div id="status">Status: Waiting to start...</div>
    <div id="trainingStatus">Training Status: ---</div>
    <div id="correlationInfo">Correlation Info: ---</div>
</div>

<div class="container webcam-section" id="webcamContainer" style="display: none;">
    <h2>2. Capture Your Image</h2>
    <video id="webcamVideo" autoplay playsinline muted></video>
    <canvas id="captureCanvas"></canvas>
    <img id="capturedImagePreview" src="#" alt="Captured Image" style="display: none;"/>
    <button id="captureButton" disabled>Capture Image</button>
    <p class="note">Allow webcam access when prompted.</p>
</div>

<div class="container prediction-section" id="predictionContainer" style="display: none;">
    <h2>3. Predict Rating</h2>
    <button id="predictButton" disabled>Predict Rating for Captured Image</button>
    <div id="predictionResult">Prediction: ---</div>
</div>

<script type="module">
    // Import Transformers.js components
    import { AutoProcessor, AutoModel, env, RawImage, Tensor } from 'https://cdn.jsdelivr.net/npm/@xenova/transformers@2.17.1';

    // --- Configuration ---
    const JSON_PATH = 'image_embeddings_rated.json'; // Assumed in same directory
    const DINO_MODEL_NAME = 'Xenova/dinov2-small';
    const EXPECTED_DINO_DIM = 384; // Expected length of the embedding array
    const NUM_TOP_FEATURES = 5; // Use top 5 correlated features
    const TF_EPOCHS = 50;
    const TF_BATCH_SIZE = 8;
    const TF_LEARNING_RATE = 0.01;

    // --- DOM Elements ---
    const loadTrainButton = document.getElementById('loadTrainButton');
    const status = document.getElementById('status');
    const trainingStatus = document.getElementById('trainingStatus');
    const correlationInfo = document.getElementById('correlationInfo');
    const webcamContainer = document.getElementById('webcamContainer');
    const webcamVideo = document.getElementById('webcamVideo');
    const captureCanvas = document.getElementById('captureCanvas');
    const captureButton = document.getElementById('captureButton');
    const capturedImagePreview = document.getElementById('capturedImagePreview');
    const predictionContainer = document.getElementById('predictionContainer');
    const predictButton = document.getElementById('predictButton');
    const predictionResult = document.getElementById('predictionResult');

    // --- State Variables ---
    let dinoProcessor = null;
    let dinoModel = null;
    let isDinoModelReady = false;
    let trainingData = null;
    let trainedModel = null;
    let topFeatureIndices = [];
    let capturedImageDataUrl = null;
    let isTraining = false;
    let actualEmbeddingLength = -1; // To store the length found in the data

    // --- Helper Functions ---
    function updateStatus(message, isError = false) {
        console.log("Status:", message);
        status.textContent = `Status: ${message}`;
        status.style.color = isError ? 'red' : '#333';
    }

    function updateTrainingStatus(message) {
        trainingStatus.textContent = `Training Status: ${message}`;
    }

     function updateCorrelationInfo(indices, correlations) {
         let text = `Top ${NUM_TOP_FEATURES} Correlated Feature Indices (Absolute Correlation):\n`;
         indices.forEach((index, i) => {
             // Check if correlation value exists before trying to format
             const corrValue = (correlations && correlations[i] !== undefined) ? correlations[i].toFixed(4) : 'N/A';
             text += `  ${i+1}. Index ${index} (Correlation: ${corrValue})\n`;
         });
         correlationInfo.textContent = text;
     }

    // --- DinoV2 Model Loading (for prediction) ---
    async function loadDinoModel() {
        updateStatus('Loading DinoV2 Processor & Model (for prediction)...');
        try {
            env.allowLocalModels = false;
            env.backends.onnx.wasm.numThreads = Math.min(navigator.hardwareConcurrency || 1, 4);
            env.allowMissingFiles = true;

            dinoProcessor = await AutoProcessor.from_pretrained(DINO_MODEL_NAME);
            dinoModel = await AutoModel.from_pretrained(DINO_MODEL_NAME, { quantized: true });
            isDinoModelReady = true;
            updateStatus('DinoV2 model ready for prediction.');
             checkPredictButtonState();
        } catch (error) {
            console.error('Error loading DinoV2 model:', error);
            updateStatus(`Error loading DinoV2 model: ${error.message}. Prediction will fail.`, true);
            isDinoModelReady = false;
        }
    }
    loadDinoModel();

    // --- Data Loading and Training ---
    loadTrainButton.addEventListener('click', handleLoadAndTrain);

    async function handleLoadAndTrain() {
        if (isTraining) return;
        isTraining = true;
        loadTrainButton.disabled = true;
        updateStatus('Loading training data...');
        updateTrainingStatus('Loading JSON...');
        correlationInfo.textContent = 'Correlation Info: ---';
        webcamContainer.style.display = 'none';
        predictionContainer.style.display = 'none';
        actualEmbeddingLength = -1; // Reset actual length

        try {
            // 1. Fetch and Parse JSON
            const response = await fetch(JSON_PATH);
            if (!response.ok) throw new Error(`HTTP error! status: ${response.status} - Could not fetch ${JSON_PATH}`);
            trainingData = await response.json();
            updateStatus('JSON data loaded. Preparing data for training...');

            // 2. Prepare Data for TF.js
            const filenames = Object.keys(trainingData);
            if (filenames.length === 0) throw new Error("JSON data is empty or invalid.");

            let embeddings = [];
            let percentages = [];

            for (const filename of filenames) {
                const item = trainingData[filename];

                // --- *** MODIFIED VALIDATION & PARSING *** ---
                // Check if embedding is a non-null object and selectionPercent is a valid number
                if (item && typeof item.embedding === 'object' && item.embedding !== null && typeof item.selectionPercent === 'number' && !isNaN(item.selectionPercent)) {

                    const embeddingObject = item.embedding;
                    const embeddingArray = [];
                    const keys = Object.keys(embeddingObject).map(Number).sort((a, b) => a - b);

                    // Infer length from the object keys (assuming they are 0, 1, 2...)
                    const inferredLength = keys.length > 0 ? keys[keys.length - 1] + 1 : 0;

                    if (inferredLength === 0) {
                        console.warn(`Skipping ${filename}: Embedding object seems empty or has non-numeric keys.`);
                        continue;
                    }

                    // Convert object values to array, ensuring keys are sequential 0 to N-1
                    let conversionOk = true;
                    for (let i = 0; i < inferredLength; i++) {
                        if (embeddingObject.hasOwnProperty(i)) {
                            embeddingArray.push(embeddingObject[i]);
                        } else {
                            console.warn(`Skipping ${filename}: Missing key ${i} in embedding object (expected sequential keys).`);
                            conversionOk = false;
                            break;
                        }
                    }

                    if (!conversionOk) continue; // Skip if keys weren't sequential

                    // Check and set the embedding length consistency
                    if (actualEmbeddingLength === -1) {
                        actualEmbeddingLength = embeddingArray.length;
                        if (actualEmbeddingLength !== EXPECTED_DINO_DIM) {
                             console.warn(`Warning: Actual embedding dimension found (${actualEmbeddingLength}) doesn't match expected DinoV2-small dimension (${EXPECTED_DINO_DIM}). Using actual dimension.`);
                        }
                    } else if (embeddingArray.length !== actualEmbeddingLength) {
                        console.warn(`Skipping ${filename}: Inconsistent embedding length (${embeddingArray.length} vs ${actualEmbeddingLength}).`);
                        continue;
                    }

                    // Add the successfully converted array and scaled percentage
                    embeddings.push(embeddingArray);
                    percentages.push(Math.min(1, Math.max(0, item.selectionPercent / 100.0)));

                } else {
                    // Log only if it's unexpected (e.g., missing keys)
                     if (!item || typeof item.embedding !== 'object' || item.embedding == null) {
                          console.warn(`Skipping invalid entry for ${filename}: Missing or invalid 'embedding' object. Data:`, item);
                     } else if (typeof item.selectionPercent !== 'number' || isNaN(item.selectionPercent)) {
                          console.warn(`Skipping invalid entry for ${filename}: Missing or invalid 'selectionPercent'. Data:`, item);
                     }
                     // Don't log every valid object that was just structured differently before parsing
                }
                 // --- *** END MODIFIED VALIDATION & PARSING *** ---
            }


            if (actualEmbeddingLength <= 0) {
                 throw new Error("Could not determine a valid embedding length from the data.");
            }
            if (embeddings.length < Math.max(NUM_TOP_FEATURES + 1, 10)) { // Need enough data
                throw new Error(`Insufficient valid data for training (need at least ${Math.max(NUM_TOP_FEATURES+1, 10)} samples with valid embeddings and selectionPercent). Found ${embeddings.length}.`);
            }
             if(actualEmbeddingLength < NUM_TOP_FEATURES) {
                  throw new Error(`Number of embedding features (${actualEmbeddingLength}) is less than the required top features (${NUM_TOP_FEATURES}).`);
             }

            const numSamples = embeddings.length;
            const numFeatures = actualEmbeddingLength; // Use the determined length
            updateStatus(`Data prepared: ${numSamples} samples, ${numFeatures} features per sample.`);

            // Convert to Tensors
            const xTensor = tf.tensor2d(embeddings, [numSamples, numFeatures]);
            const yTensor = tf.tensor1d(percentages);

             // 3. Feature Selection based on Correlation
             updateTrainingStatus('Calculating feature correlations...');
             await tf.nextFrame();

             const correlations = [];
             const yMeanTensor = yTensor.mean();
             const yStdDevTensor = tf.sqrt(yTensor.sub(yMeanTensor).square().mean());
             const yMean = yMeanTensor.dataSync()[0];
             const yStdDev = yStdDevTensor.dataSync()[0];

             yMeanTensor.dispose(); // Dispose intermediate tensors
             yStdDevTensor.dispose();

             if (yStdDev === 0) {
                // Handle gracefully: If no variance, maybe default to first N features? Or error out.
                console.warn("Target variable (selectionPercent) has zero variance. Correlation is undefined. Using first N features.");
                topFeatureIndices = Array.from({ length: NUM_TOP_FEATURES }, (_, i) => i);
                updateCorrelationInfo(topFeatureIndices, null); // Indicate correlation wasn't calculated
             } else {
                 // Calculate correlations only if variance exists
                 for (let j = 0; j < numFeatures; j++) {
                    await tf.tidy(() => { // Use tidy to manage memory for feature columns
                        const featureCol = xTensor.slice([0, j], [numSamples, 1]).reshape([numSamples]);
                        const xMean = featureCol.mean().dataSync()[0];
                        const xStdDevTensor = tf.sqrt(featureCol.sub(xMean).square().mean());
                        const xStdDev = xStdDevTensor.dataSync()[0];

                        let correlation = 0;
                        if (xStdDev > 0) {
                            const covariance = featureCol.sub(xMean).mul(yTensor.sub(yMean)).mean().dataSync()[0];
                            correlation = covariance / (xStdDev * yStdDev);
                        }
                        correlations.push({ index: j, value: isNaN(correlation) ? 0 : correlation });
                        // featureCol is disposed by tidy
                        // xStdDevTensor is implicitly disposed by tidy
                    });
                    if (j % 50 === 0) await tf.nextFrame(); // Yield occasionally for large features
                 }
                 correlations.sort((a, b) => Math.abs(b.value) - Math.abs(a.value));
                 topFeatureIndices = correlations.slice(0, NUM_TOP_FEATURES).map(c => c.index);
                 const topCorrelations = correlations.slice(0, NUM_TOP_FEATURES).map(c => c.value);
                 updateCorrelationInfo(topFeatureIndices, topCorrelations);
             }


             updateStatus(`Identified top ${NUM_TOP_FEATURES} features. Preparing final training data.`);

             // Filter xTensor to keep only top features
             const xTensorTopFeatures = xTensor.gather(topFeatureIndices, 1);

            // 4. Define and Train Logistic Regression Model
            updateTrainingStatus('Defining TF.js model...');
             await tf.nextFrame();

             trainedModel = tf.sequential();
             trainedModel.add(tf.layers.dense({
                inputShape: [NUM_TOP_FEATURES],
                units: 1,
                activation: 'sigmoid'
             }));

            trainedModel.compile({
                 optimizer: tf.train.adam(TF_LEARNING_RATE),
                 loss: tf.losses.binaryCrossentropy,
                 metrics: ['accuracy']
             });

            updateTrainingStatus(`Training model for ${TF_EPOCHS} epochs...`);
            await tf.nextFrame();

            const history = await trainedModel.fit(xTensorTopFeatures, yTensor, {
                epochs: TF_EPOCHS,
                batchSize: TF_BATCH_SIZE,
                callbacks: {
                    onEpochEnd: async (epoch, logs) => {
                         updateTrainingStatus(`Training... Epoch ${epoch + 1}/${TF_EPOCHS}, Loss: ${logs.loss.toFixed(4)}`);
                         console.log(`Epoch ${epoch + 1}`, logs);
                         await tf.nextFrame(); // Prevent blocking UI during training loops
                    }
                }
            });

            // Clean up tensors
            xTensor.dispose();
            yTensor.dispose();
            xTensorTopFeatures.dispose();


            updateTrainingStatus('Model training complete!');
            updateStatus('Model trained successfully. Ready for webcam capture.');
            webcamContainer.style.display = 'block';
            predictionContainer.style.display = 'block';
            startWebcam();

        } catch (error) {
            console.error("Error during loading or training:", error);
            updateStatus(`Error: ${error.message}`, true);
            updateTrainingStatus('Failed.');
            trainedModel = null;
        } finally {
            isTraining = false;
            loadTrainButton.disabled = false;
        }
    }


    // --- Webcam Handling ---
    async function startWebcam() {
        if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
            updateStatus("Webcam access not supported by this browser.", true);
            captureButton.disabled = true;
            return;
        }
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user' } });
            webcamVideo.srcObject = stream;
            webcamVideo.onloadedmetadata = () => {
                captureButton.disabled = false;
                 updateStatus('Webcam started. Position yourself and capture.');
                 captureCanvas.width = webcamVideo.videoWidth;
                 captureCanvas.height = webcamVideo.videoHeight;
            };
        } catch (err) {
            console.error("Error accessing webcam:", err);
            updateStatus(`Error accessing webcam: ${err.message}. Check browser permissions.`, true);
            captureButton.disabled = true;
        }
    }

    captureButton.addEventListener('click', () => {
         if (webcamVideo.srcObject && webcamVideo.readyState >= 3) {
             const context = captureCanvas.getContext('2d');
             context.drawImage(webcamVideo, 0, 0, captureCanvas.width, captureCanvas.height);
             capturedImageDataUrl = captureCanvas.toDataURL('image/jpeg');
             capturedImagePreview.src = capturedImageDataUrl;
             capturedImagePreview.style.display = 'block';
             updateStatus('Image captured. Ready to predict.');
             checkPredictButtonState();
         } else {
             updateStatus('Webcam not ready yet.', true);
         }
    });

    // --- Prediction ---
    predictButton.addEventListener('click', predictWebcamImage);

    function checkPredictButtonState() {
        predictButton.disabled = !(isDinoModelReady && trainedModel && capturedImageDataUrl);
    }

    async function getDinoEmbedding(imageDataUrl) {
        if (!isDinoModelReady || !dinoProcessor || !dinoModel) throw new Error("DinoV2 model/processor not ready.");

        let embeddingArray = null;
        try {
            await tf.tidy(async () => { // Use tidy for transformers.js tensors too
                const image = await RawImage.fromURL(imageDataUrl);
                const inputs = await dinoProcessor(image);
                const output = await dinoModel(inputs);

                if (!output || !output.last_hidden_state) throw new Error("Failed to get 'last_hidden_state' from DinoV2 model output.");

                const lastHiddenState = output.last_hidden_state; // This is a Transformers.js Tensor

                if (lastHiddenState.dims.length !== 3 || lastHiddenState.dims[0] !== 1) throw new Error("Invalid 'last_hidden_state' format from DinoV2.");

                const hidden_dim = lastHiddenState.dims[2];
                const tensorData = await lastHiddenState.data; // Get the Float32Array data

                // Slice directly from the Float32Array
                const clsEmbeddingData = tensorData.slice(0, hidden_dim);

                if (clsEmbeddingData.length !== hidden_dim) throw new Error("Failed to extract correct CLS embedding slice from DinoV2 data.");

                embeddingArray = Array.from(clsEmbeddingData); // Convert Float32Array to regular array for consistency if needed, though Float32Array is fine too.
                // lastHiddenState tensor will be disposed by tidy
            });
            return embeddingArray; // Return the regular array or Float32Array slice
        } catch (error) {
            console.error("Error getting DinoV2 embedding:", error);
            throw error;
        }
    }


    async function predictWebcamImage() {
        if (!trainedModel || !capturedImageDataUrl || !isDinoModelReady) {
            updateStatus("Cannot predict: Model not trained, image not captured, or DinoV2 not ready.", true);
            return;
        }
        if (!topFeatureIndices || topFeatureIndices.length !== NUM_TOP_FEATURES) {
             updateStatus("Cannot predict: Top feature indices not determined correctly.", true);
            return;
        }

        predictButton.disabled = true;
        predictionResult.textContent = 'Prediction: Processing...';
        updateStatus('Calculating embedding for captured image...');

        try {
            // 1. Get DinoV2 embedding for the captured image
            const fullEmbedding = await getDinoEmbedding(capturedImageDataUrl); // Returns Float32Array or Array

            if (!fullEmbedding || fullEmbedding.length !== actualEmbeddingLength) {
                 throw new Error(`Failed to get valid full embedding or length mismatch (${fullEmbedding?.length} vs ${actualEmbeddingLength}).`);
            }

             // 2. Extract only the top features used during training
             const inputFeatures = topFeatureIndices.map(index => {
                 if (index >= fullEmbedding.length || index < 0) {
                     throw new Error(`Invalid feature index ${index} for embedding length ${fullEmbedding.length}.`);
                 }
                 return fullEmbedding[index];
             });


             if (inputFeatures.some(val => val === undefined || isNaN(val))) {
                 throw new Error("Could not extract all required features from the embedding (undefined/NaN found).");
             }

            // 3. Prepare tensor for TF.js model
            const inputTensor = tf.tensor2d([inputFeatures], [1, NUM_TOP_FEATURES]);

            // 4. Predict using the trained TF.js model
            updateStatus('Predicting rating using the trained model...');
            const predictionTensor = trainedModel.predict(inputTensor);
            const predictionValue = predictionTensor.dataSync()[0];

            // 5. Scale back to 0-100 and display
            const predictedPercent = (predictionValue * 100).toFixed(1);
            predictionResult.textContent = `Predicted Rating: ${predictedPercent}%`;
            updateStatus('Prediction complete.');

            // Clean up tensors
            inputTensor.dispose();
            predictionTensor.dispose();

        } catch (error) {
            console.error("Prediction Error:", error);
            updateStatus(`Prediction failed: ${error.message}`, true);
            predictionResult.textContent = 'Prediction: Error';
        } finally {
             checkPredictButtonState();
        }
    }

    checkPredictButtonState();

</script>

</body>
</html>
